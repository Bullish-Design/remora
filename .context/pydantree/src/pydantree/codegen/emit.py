from __future__ import annotations

from datetime import UTC, datetime
from pathlib import Path

from pydantic import BaseModel, ConfigDict

from pydantree.codegen.common import CodegenDiagnosticError
from pydantree.codegen.normalize import NormalizeOutput


class EmittedModule(BaseModel):
    model_config = ConfigDict(frozen=True)

    module_name: str
    file_path: str
    content_sha256: str


class EmitOutput(BaseModel):
    model_config = ConfigDict(frozen=True)

    generated_at: datetime
    output_dir: str
    modules: tuple[EmittedModule, ...]


def emit_models(payload: NormalizeOutput, output_dir: Path) -> EmitOutput:
    from hashlib import sha256

    if not payload.queries:
        raise CodegenDiagnosticError(
            "emit",
            "Normalize output has no queries to emit.",
            hint="Run normalize with valid ingest output first.",
        )

    output_dir.mkdir(parents=True, exist_ok=True)
    modules: list[EmittedModule] = []

    for query in payload.queries:
        module_name = f"{query.provenance.language}_{query.provenance.query_type}_models".replace("-", "_")
        file_path = output_dir / f"{module_name}.py"
        body = _render_query_module(query)
        file_path.write_text(body, encoding="utf-8")
        modules.append(
            EmittedModule(
                module_name=module_name,
                file_path=file_path.as_posix(),
                content_sha256=sha256(body.encode("utf-8")).hexdigest(),
            )
        )

    return EmitOutput(generated_at=datetime.now(UTC), output_dir=output_dir.as_posix(), modules=tuple(modules))


def _render_query_module(query: object) -> str:
    # Import locally for a smaller dependency surface in generated code paths.
    from pydantree.codegen.normalize import NormalizedQuery

    normalized_query = NormalizedQuery.model_validate(query)
    patterns_literal = []
    for pattern in normalized_query.patterns:
        captures_literal = ",\n            ".join(
            f'Capture(capture_id="{capture.capture_id}", name="{capture.name}")' for capture in pattern.captures
        )
        if not captures_literal:
            captures_literal = ""
        patterns_literal.append(
            "Pattern(\n"
            f'            pattern_id="{pattern.pattern_id}",\n'
            f'            source={pattern.source!r},\n'
            "            captures=(\n"
            f"            {captures_literal}\n"
            "            ),\n"
            "        )"
        )

    patterns_body = ",\n        ".join(patterns_literal)

    return (
        '"""Generated by pydantree.codegen.emit. DO NOT EDIT MANUALLY."""\n\n'
        "from pydantic import BaseModel\n\n\n"
        "class Capture(BaseModel):\n"
        "    capture_id: str\n"
        "    name: str\n\n\n"
        "class Pattern(BaseModel):\n"
        "    pattern_id: str\n"
        "    source: str\n"
        "    captures: tuple[Capture, ...]\n\n\n"
        "class Query(BaseModel):\n"
        "    source_file: str\n"
        "    language: str\n"
        "    query_type: str\n"
        "    patterns: tuple[Pattern, ...]\n\n\n"
        "QUERY_MODEL = Query(\n"
        f"    source_file={normalized_query.provenance.file_path!r},\n"
        f"    language={normalized_query.provenance.language!r},\n"
        f"    query_type={normalized_query.provenance.query_type!r},\n"
        "    patterns=(\n"
        f"        {patterns_body}\n"
        "    ),\n"
        ")\n"
    )
