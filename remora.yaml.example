# Remora configuration example
# Copy to remora.yaml and adjust as needed.

discovery:
  language: python
  query_pack: remora_core
  # query_dir: null  # Use built-in queries (default). Set to override.

agents_dir: agents

# vLLM server on your Tailscale network
# vLLM server on your Tailscale network
server:
  base_url: "http://remora-server:8000/v1"
  api_key: "EMPTY"
  timeout: 120
  default_adapter: "google/functiongemma-270m-it"
  retry:
    max_attempts: 3
    initial_delay: 1.0
    max_delay: 30.0
    backoff_factor: 2.0

operations:
  lint:
    enabled: true
    priority: "normal"
    auto_accept: false
    subagent: lint
    # model_id here is the LoRA adapter name on the server
    # omit to use server.default_adapter
    # model_id: "lint"

  test:
    enabled: true
    priority: "high"
    auto_accept: false
    subagent: test

  docstring:
    enabled: true
    priority: "normal"
    auto_accept: false
    subagent: docstring
    style: google

  sample_data:
    enabled: false
    priority: "low"
    auto_accept: false
    subagent: sample_data

runner:
  max_turns: 20
  max_tokens: 512
  temperature: 0.1
  tool_choice: "required"  # "required" | "auto" | "none"
  max_history_messages: 50

cairn:
  # command: cairn  # Removed (using in-process execution)
  home: null
  max_concurrent_agents: 16
  timeout: 300
  pool_workers: 4
  limits_preset: "default"  # strict | default | permissive
  max_queue_size: 100
  # limits_override:
  #   max_memory: "32mb"

event_stream:
  enabled: false
  include_payloads: true
  max_payload_chars: 4000

watch:
  extensions: [".py"]
  ignore_patterns:
    - "__pycache__"
    - ".git"
    - ".jj"
    - ".venv"
    - "node_modules"
    - ".remora_cache"
    - ".agentfs"
  debounce_ms: 500
